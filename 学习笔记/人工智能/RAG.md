# RAG - Retrieval Augmented Generation

![](i/chat_use_case-eb8a4883931d726e9f23628a0d22e315.png)

RAG 早在 GPT 等 LLMs 出来之前就有了相关的研究。例如 FaceBook 在 2020 年的研究尝试 ，将模型知识分为两类** 参数记忆**（内部信息） 和 **非参记忆**（外部信息） ，基于这些知识来产出内容

首创：[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)

RAG方式有其灵活性,即使模型**参数不变**也能适应快速变化的**外部信息**

外部数据可以是文档、数据库、网页信息、个人知识库、日志、图文视频也可以是从API获取的数据等等

这些外部信息的处理方式通常是**切块**然后做**向量化**表征然后在向量数据库中基于用户输入做**检索**

PS：向量数据库只是一种候选，还可以有更多选择，可以泛化为一个信息检索系统

大模型使用外部数据可以提供更准确和及时的回复，同时减少模型猜测输出的可能性即**幻觉**，增强用户的信任度

PS：有研究者指出幻觉是让大模型产出创意的基础，现在大家都在思考如何消除幻觉，其实另一个方向也可做利用


**目前看来，RAG 是当前大语言模型场景下最有效的整合最新可验证信息的方式，且无需重新训练和更新以保持较小成本**