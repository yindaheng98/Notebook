# 一些常见的模型量化方法

## 前言

>### 什么是量化？
>将高精度运算转化到低精度上运算，例如float32转化为int8数据上运算。
>
>### 为什么要量化？
>那就要说说量化的好处了，一般量化有以下好处：
>* 减小模型尺寸和存储空间，如int8量化可减少75%的模型大小；
>* 加快推理速度，访问一次32位浮点型可以访问四次int8型，运算更快；
>* 减少设备功耗，内存耗用少了推理速度快了自然减少了设备功耗；
>* 支持微处理器，有些微处理器属于8位的，低功耗运行浮点运算速度慢，需要进行8bit量化；
>
>但是其也有一些缺点：
>
>* 增加了操作复杂度，有时会有一些特殊处理，甚至会有tradeoff，比如你发明了一个牛13的算子，可惜现有的量化工具不支持，自己实现又头大，只能忍痛割爱；
>* 会损失一定的精度，所以有时会有微调，但也会有损失；不过值得一提的是，每次我用openvino量化，精度不降低反而还会升高一丢丢。这是因为模型参数是非常冗余的，量化可以看成一种正则化技术，会提升模型的泛化能力，可能在测试集上会表现好一点。不过都是事后诸葛的理论分析了，具体还是要看测试指标的。
>
>### 怎么量化？
>虽然量化方法很多，但并无本质区别。记住一点就可以了：将高精度数据映射到低精度表达，在低精度上运算，然后再反量化回去，因为最终的输出我们还是要高精度的数据的。

——摘自[《pytorch量化备忘录》](https://zhuanlan.zhihu.com/p/269808112)

需要注意的是，量化的方法根据其量化目的的不同而有很大的区别：
* 针对计算的量化：主要的需求是减小模型的计算量，要求特征图直接以量化的形式进行计算
* 针对压缩的量化：主要的需求是减小模型或特征占用的空间，特征图不需要以量化的形式进行计算

这两种量化目的带来的最大区别在于量化映射的线性和非线性：
* 线性映射：$y=ax+b$，量化之后的数值进行加减乘除等计算与不量化直接计算在数学上等价(比如做加法：$x_1+x_2=y_1/a_1+y_2/a_2-b_1/a_1-b_2/a_2$)
* 非线性映射：量化之后的数值进行加减乘除计算后与不量化直接计算在数学上不一定等价

所以很显然，针对计算的量化只能进行线性映射，而针对压缩的量化还可以进行非线性映射。

而在神经网络的计算过程中，特征图上的概率分布大都是非线性的，通常接近与正态分布或指数分布，非线性映射可以处理这种非均匀分布的情况。所以如果不涉及量化计算（模型参数量化等任务），通常用非线性映射的量化（特征压缩等任务）。

## 参数量化：线性映射

## 特征压缩：非线性映射
